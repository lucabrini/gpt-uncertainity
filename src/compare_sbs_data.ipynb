{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Step by Step data sets\n",
    "\n",
    "Compare resurrected items between the data generated with k=5, k=10, k=20 samples for GPT3-turbo and k=5 samples for GPT4o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load sbs data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "from utils import group_entropies_by_dialogue_id, has_resurrected_items, group_sbs_data_by_dialogue_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "five_samples_data_path = \"./data/generation/8_mcrae/sbs_entropy_k_five.csv\"\n",
    "ten_samples_data_path = \"./data/generation/8_mcrae/sbs_entropy_k_ten.csv\"\n",
    "twenty_samples_data_path = \"./data/generation/8_mcrae/sbs_entropy_k_twenty.csv\"\n",
    "five_gpt4o_samples_data_path = \"./data/generation/8_mcrae/sbs_entropy_k_five_gpt4o.csv\"\n",
    "ten_gpt4o_samples_data_path = \"./data/generation/8_mcrae/sbs_entropy_k_ten_gpt4o.csv\"\n",
    "\n",
    "five_rf = open(five_samples_data_path, 'r', newline='')\n",
    "ten_rf = open(ten_samples_data_path, 'r', newline='')\n",
    "twenty_rf = open(twenty_samples_data_path, 'r', newline='')\n",
    "five_gpt4o_rf = open(five_gpt4o_samples_data_path, 'r', newline='')\n",
    "ten_gpt4o_rf = open(ten_gpt4o_samples_data_path, 'r', newline='')\n",
    "\n",
    "five_reader = csv.DictReader(five_rf, delimiter=\",\")\n",
    "ten_reader = csv.DictReader(ten_rf, delimiter=\",\")\n",
    "twenty_reader = csv.DictReader(twenty_rf, delimiter=\",\")\n",
    "five_gpt4o_reader = csv.DictReader(five_gpt4o_rf, delimiter=\",\")\n",
    "ten_gpt4o_reader = csv.DictReader(ten_gpt4o_rf, delimiter=\",\")\n",
    "\n",
    "five_entropies, _ = group_entropies_by_dialogue_id(five_reader)\n",
    "ten_entropies, _ = group_entropies_by_dialogue_id(ten_reader)\n",
    "twenty_entropies, _ = group_entropies_by_dialogue_id(twenty_reader)\n",
    "five_gpt4o_entropies, _ = group_entropies_by_dialogue_id(five_gpt4o_reader)\n",
    "ten_gpt4o_entropies, _ = group_entropies_by_dialogue_id(ten_gpt4o_reader)\n",
    "\n",
    "five_rf.close()\n",
    "ten_rf.close()\n",
    "twenty_rf.close()\n",
    "five_gpt4o_rf.close()\n",
    "ten_gpt4o_rf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count dialogues with resurrected items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resurrected items GPT3 (k=5, k=10, k=20):  78 77 82\n",
      "Resurrected items GPT4o (k=5, k=10):  33 40\n"
     ]
    }
   ],
   "source": [
    "five_samples_resurrected_items_count = 0\n",
    "ten_samples_resurrected_items_count = 0\n",
    "twenty_samples_resurrected_items_count = 0\n",
    "five_gpt4o_samples_resurrected_items_count = 0\n",
    "ten_gpt4o_samples_resurrected_items_count = 0\n",
    "\n",
    "for dialogue_id in five_entropies:\n",
    "    dialogue_entropies = five_entropies[dialogue_id]\n",
    "    if(has_resurrected_items(dialogue_entropies)):\n",
    "      five_samples_resurrected_items_count += 1\n",
    "      \n",
    "for dialogue_id in ten_entropies:\n",
    "    dialogue_entropies = ten_entropies[dialogue_id]\n",
    "    if(has_resurrected_items(dialogue_entropies)):\n",
    "      ten_samples_resurrected_items_count += 1\n",
    "\n",
    "for dialogue_id in twenty_entropies:\n",
    "    dialogue_entropies = twenty_entropies[dialogue_id]\n",
    "    if(has_resurrected_items(dialogue_entropies)):\n",
    "      twenty_samples_resurrected_items_count += 1\n",
    "\n",
    "for dialogue_id in five_gpt4o_entropies:\n",
    "    dialogue_entropies = five_gpt4o_entropies[dialogue_id]\n",
    "    if(has_resurrected_items(dialogue_entropies)):\n",
    "      five_gpt4o_samples_resurrected_items_count += 1\n",
    "\n",
    "for dialogue_id in ten_gpt4o_entropies:\n",
    "    dialogue_entropies = ten_gpt4o_entropies[dialogue_id]\n",
    "    if(has_resurrected_items(dialogue_entropies)):\n",
    "      ten_gpt4o_samples_resurrected_items_count += 1\n",
    "      \n",
    "print(\"Resurrected items GPT3 (k=5, k=10, k=20): \", five_samples_resurrected_items_count, ten_samples_resurrected_items_count, twenty_samples_resurrected_items_count)\n",
    "print(\"Resurrected items GPT4o (k=5, k=10): \", five_gpt4o_samples_resurrected_items_count, ten_gpt4o_samples_resurrected_items_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute resurrected items percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'five_samples': {'resurrected_items_count': 78, 'percentage': 0.8863636363636364}, 'ten_samples': {'resurrected_items_count': 77, 'percentage': 0.875}, 'twenty_samples': {'resurrected_items_count': 82, 'percentage': 0.9318181818181818}, 'five_samples_gpt4o': {'resurrected_items_count': 33, 'percentage': 0.375}, 'ten_samples_gpt4o': {'resurrected_items_count': 40, 'percentage': 0.45454545454545453}}\n"
     ]
    }
   ],
   "source": [
    "output = {\n",
    "  \"five_samples\" : {\n",
    "    \"resurrected_items_count\" : five_samples_resurrected_items_count,\n",
    "    \"percentage\" : five_samples_resurrected_items_count/len(five_entropies) # / 88\n",
    "  },\n",
    "  \"ten_samples\" : {\n",
    "    \"resurrected_items_count\" : ten_samples_resurrected_items_count,\n",
    "    \"percentage\" : ten_samples_resurrected_items_count/len(ten_entropies) # / 88\n",
    "  },\n",
    "    \"twenty_samples\" : {\n",
    "    \"resurrected_items_count\" : twenty_samples_resurrected_items_count,\n",
    "    \"percentage\" : twenty_samples_resurrected_items_count/len(twenty_entropies) # / 88\n",
    "  },\n",
    "    \"five_samples_gpt4o\" : {\n",
    "    \"resurrected_items_count\" : five_gpt4o_samples_resurrected_items_count,\n",
    "    \"percentage\" : five_gpt4o_samples_resurrected_items_count/len(five_gpt4o_entropies) # / 88\n",
    "  },\n",
    "    \"ten_samples_gpt4o\" : {\n",
    "    \"resurrected_items_count\" : ten_gpt4o_samples_resurrected_items_count,\n",
    "    \"percentage\" : ten_gpt4o_samples_resurrected_items_count/len(ten_gpt4o_entropies) # / 88\n",
    "  }\n",
    "  \n",
    "}\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute probability of resurrected items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping sbs data by dialogue id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "five_samples_sbs_data_path = \"./data/generation/8_mcrae/dialogues_sbs_k_five_distr_ver2.csv\"\n",
    "ten_samples_sbs_data_path = \"./data/generation/8_mcrae/dialogues_sbs_k_ten_distr_ver2.csv\"\n",
    "twenty_samples_sbs_data_path = \"./data/generation/8_mcrae/dialogues_sbs_k_twenty_distr.csv\"\n",
    "five_gpt4o_samples_sbs_data_path = \"./data/generation/8_mcrae/dialogues_sbs_k_five_gpt4o.csv\"\n",
    "ten_gpt4o_samples_sbs_data_path = \"./data/generation/8_mcrae/dialogues_sbs_k_ten_gpt4o.csv\"\n",
    "\n",
    "# grouping row together by dialogue id\n",
    "\n",
    "five_rf = open(five_samples_sbs_data_path, 'r', newline='')\n",
    "five_reader = csv.DictReader(five_rf, delimiter=\",\")\n",
    "five_data = group_sbs_data_by_dialogue_id(five_reader)\n",
    "\n",
    "ten_rf = open(ten_samples_sbs_data_path, 'r', newline='')\n",
    "ten_reader = csv.DictReader(ten_rf, delimiter=\",\")\n",
    "ten_data = group_sbs_data_by_dialogue_id(ten_reader)\n",
    "\n",
    "twenty_rf = open(twenty_samples_sbs_data_path, 'r', newline='')\n",
    "twenty_reader = csv.DictReader(twenty_rf, delimiter=\",\")\n",
    "twenty_data = group_sbs_data_by_dialogue_id(twenty_reader)\n",
    "\n",
    "five_gpt4o_rf = open(five_gpt4o_samples_sbs_data_path, 'r', newline='')\n",
    "five_gpt4o_reader = csv.DictReader(five_gpt4o_rf, delimiter=\",\")\n",
    "five_gpt4o_data = group_sbs_data_by_dialogue_id(five_gpt4o_reader)\n",
    "\n",
    "ten_gpt4o_rf = open(ten_gpt4o_samples_sbs_data_path, 'r', newline='')\n",
    "ten_gpt4o_reader = csv.DictReader(ten_gpt4o_rf, delimiter=\",\")\n",
    "ten_gpt4o_data = group_sbs_data_by_dialogue_id(ten_gpt4o_reader)\n",
    "# print(ten_gpt4o_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each dialogue step, find resurrected items and compute the sum of their probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resurrected avg GPT3 (k=5, k=10, k=20):  0.11246965888689413 0.09104739676840211 0.07166732495511678\n",
      "Resurrected avg GPT4o (k=5, k=10):  0.046403590664272895 0.05322728904847397\n"
     ]
    }
   ],
   "source": [
    "def compute_resurrected_items_p_sum(grouped_data):\n",
    "  p_summatory = 0\n",
    "  counter = 0\n",
    "  for dialogue_id, dialogue in enumerate(grouped_data):\n",
    "    #print(\"DIALOGUE: , \", dialogue[\"dialogue_id\"])\n",
    "    intra_dialogues = dialogue[\"intra_dialogues\"]\n",
    "    for i in range(0, len(dialogue[\"intra_dialogues\"])):\n",
    "      resurrected_items = []\n",
    "      resurrected_p = 0\n",
    "      \n",
    "      if(i != 0):\n",
    "        current_distr = intra_dialogues[i][\"p_distribuition\"]\n",
    "        previous_distr = intra_dialogues[i-1][\"p_distribuition\"]\n",
    "        \n",
    "        # finding resurrected items\n",
    "        for item in list(current_distr.keys()):\n",
    "          if(previous_distr[item] == 0 and current_distr[item] > previous_distr[item]):\n",
    "            resurrected_items.append(item)\n",
    "        \n",
    "        for item in resurrected_items:\n",
    "          resurrected_p += current_distr[item]\n",
    "          \n",
    "        p_summatory += resurrected_p\n",
    "        counter += 1\n",
    "        \n",
    "      grouped_data[dialogue_id][\"intra_dialogues\"][i][\"resurrected_items\"] = resurrected_items\n",
    "      grouped_data[dialogue_id][\"intra_dialogues\"][i][\"resurrected_items_p\"] = resurrected_p\n",
    "  \n",
    "  resurrected_p_average = p_summatory / counter\n",
    "  \n",
    "  return grouped_data, resurrected_p_average\n",
    "\n",
    "five_analyzed_data, five_r_p_average = compute_resurrected_items_p_sum(five_data)\n",
    "ten_analyzed_data, ten_r_p_average = compute_resurrected_items_p_sum(ten_data)\n",
    "twenty_analyzed_data, twenty_r_p_average = compute_resurrected_items_p_sum(twenty_data)\n",
    "five_gpt4o_analyzed_data, five_gpt4o_r_p_average = compute_resurrected_items_p_sum(five_gpt4o_data)\n",
    "ten_gpt4o_analyzed_data, ten_gpt4o_r_p_average = compute_resurrected_items_p_sum(ten_gpt4o_data)\n",
    "print(\"Resurrected avg GPT3 (k=5, k=10, k=20): \", five_r_p_average, ten_r_p_average, twenty_r_p_average)\n",
    "print(\"Resurrected avg GPT4o (k=5, k=10): \", five_gpt4o_r_p_average, ten_gpt4o_r_p_average)\n",
    "# print(five_gpt4o_analyzed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump(path, grouped_data):\n",
    "  with open(path, \"w\") as f:\n",
    "    for dialogue in grouped_data:\n",
    "      dialogue_id = dialogue[\"dialogue_id\"]\n",
    "      intra_dialogues = dialogue[\"intra_dialogues\"]\n",
    "      for step in intra_dialogues:\n",
    "        \n",
    "        for r_item in step[\"resurrected_items\"]:\n",
    "          step[\"p_distribuition\"].pop(r_item)\n",
    "          \n",
    "        step[\"p_distribuition\"][\"resurrected_items_p\"] = step[\"resurrected_items_p\"]\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\n",
    "          dialogue_id,\n",
    "          step[\"intra_dialogue_id\"],\n",
    "          step[\"p_distribuition\"],\n",
    "          step[\"resurrected_items\"],\n",
    "          step[\"resurrected_items_p\"]\n",
    "        ])\n",
    "        \n",
    "dump(\"./data/generation/8_mcrae/dialogues_sbs_k_five_distr_w_resurr_p.csv\", five_analyzed_data)\n",
    "dump(\"./data/generation/8_mcrae/dialogues_sbs_k_ten_distr_w_resurr_p.csv\", ten_analyzed_data)\n",
    "dump(\"./data/generation/8_mcrae/dialogues_sbs_k_twenty_distr_w_resurr_p.csv\", twenty_analyzed_data)\n",
    "dump(\"./data/generation/8_mcrae/dialogues_sbs_k_five_gpt4o_distr_w_resurr_p.csv\", five_gpt4o_data)\n",
    "dump(\"./data/generation/8_mcrae/dialogues_sbs_k_ten_gpt4o_distr_w_resurr_p.csv\", ten_gpt4o_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian apocalypse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero distribution GPT3 (k=5, k=10, k=20):  (644, 0) (644, 0) (644, 0)\n",
      "Zero distribution GPT4o (k=5, k=10):  (644, 53) (644, 46)\n"
     ]
    }
   ],
   "source": [
    "def count_zero_distr(data):\n",
    "  zeros_list = np.zeros(8)\n",
    "  count_zero_distr = 0\n",
    "  total = 0\n",
    "  for dialogue_id, dialogue in enumerate(data):\n",
    "    intra_dialogues = dialogue[\"intra_dialogues\"]\n",
    "    for i in range(0, len(dialogue[\"intra_dialogues\"])):\n",
    "      total += 1\n",
    "      current_distr = intra_dialogues[i][\"p_distribuition\"]\n",
    "      if np.array_equal(zeros_list, list(current_distr.values())):\n",
    "        count_zero_distr += 1\n",
    "  return total, count_zero_distr\n",
    "\n",
    "print(\"Zero distribution GPT3 (k=5, k=10, k=20): \", count_zero_distr(five_data), count_zero_distr(ten_data), count_zero_distr(twenty_data))\n",
    "print(\"Zero distribution GPT4o (k=5, k=10): \", count_zero_distr(five_gpt4o_data), count_zero_distr(ten_gpt4o_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error k=5: 21\n",
      "Error k=10: 24\n"
     ]
    }
   ],
   "source": [
    "def dump_dialogue_error(path, grouped_data):\n",
    "  count_err = 0\n",
    "  with open(path, \"w\") as f:\n",
    "    csv.writer(f).writerow([\n",
    "      \"dialogue_id\",\n",
    "      \"intra_dialogue_id\",\n",
    "      \"question\",\n",
    "      \"answer\",\n",
    "      \"target\",\n",
    "      \"canditates\",\n",
    "      \"dist\"\n",
    "    ])\n",
    "    for dialogue in grouped_data:\n",
    "      dialogue_id = dialogue[\"dialogue_id\"]\n",
    "      intra_dialogues = dialogue[\"intra_dialogues\"]\n",
    "      for step in intra_dialogues:\n",
    "        dist = list(step[\"p_distribuition\"].values())\n",
    "        canditates = list(step[\"p_distribuition\"].keys())\n",
    "        target = step[\"target\"]\n",
    "        if dist != [0, 0, 0, 0, 0, 0, 0, 0]:\n",
    "          entropy = sp.stats.entropy(dist)\n",
    "        if (entropy == 0 and target != canditates[np.argmax(dist)]) or dist == [0, 0, 0, 0, 0, 0, 0, 0]:\n",
    "          if entropy == 0 and target != canditates[np.argmax(dist)] and dist != [0, 0, 0, 0, 0, 0, 0, 0]:\n",
    "              count_err += 1\n",
    "          writer = csv.writer(f)\n",
    "          writer.writerow([\n",
    "            dialogue_id,\n",
    "            step[\"intra_dialogue_id\"],\n",
    "            step[\"question\"],\n",
    "            step[\"answer\"],\n",
    "            target,\n",
    "            canditates,\n",
    "            dist\n",
    "          ])\n",
    "    return count_err\n",
    "\n",
    "# print(len(five_gpt4o_data))\n",
    "print(\"Error k=5:\", dump_dialogue_error(\"./data/generation/8_mcrae/dialogues_error_target_gpt4o_k_five.csv\", five_gpt4o_data))\n",
    "print(\"Error k=10:\", dump_dialogue_error(\"./data/generation/8_mcrae/dialogues_error_target_gpt4o_k_ten.csv\", ten_gpt4o_data))\n",
    "\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
